# LLM-learning
生成式AI  --- AI Agent ---Agentic AI演进

### AI Agent 定义：
在限定的数字环境中执行目标导向任务的自主软件实体，具备感知结构化或非结构化输入、对上下文信息进行推理、以及为实现特定目标而采取行动的能力。  
  • 单个的、能使用工具的智能助手；  
  • 基于大型语言模型 LLM（或LIM），通过工具集成（如 API 调用、函数调用）、提示工程和增强的推理能力，实现特定、界限明确任务的自动化；  
  • 是生成式 AI 在任务执行能力上的延伸；
 
### Agentic AI 定义：多个专业化的智能体组成的协作系统，利用协同推理和多步骤规划来实现复杂、高层次的目标。  
• 是多个具备专长、能互相协作的智能助手组成的“团队”；  
• 通过结构化通信、共享内存 和动态角色分配，多个智能实体能够协同处理目标；  
• 从孤立的单智能体到多智能体协同的系统，扩展了传统 AI Agent 的能力，可以解决更复杂、更大范围的问题；

### Agentic AI的架构演进：  
1）多个Agent构成，每个Agent负责一个专门的功能或任务，Agent间通过通信通道（消息总线、共享内存等）交互，Agent是角色绑定的  
2）高级推理和规划：通过 ReAct、CoT 等技术增强迭代推理能力，将复杂任务分解为多个推理阶段， 评估中间结果，并动态地重新规划动作，从而能够自适应地响应不确定性或部分故障。  
3）融入记忆子系统，从而可以跨任务周期或智能体会话保存和持久化知识。记忆类型包括场景记忆（任务历史）、语义记忆（事实或结构化数据）以及 RAG 向量化记忆。  
4）编排器/元Agent：协调下属智能体的生命周期、管理依赖关系、分配角色和解决冲突。包括任务管理器、评估器或协调

### Agent的四个模块：  
#### 记忆模块：可完成任务的时间纵向长度 LangChain  
    感知记忆：输入的文本，多模态解析内容  
    短期记忆：常见提示工程，直接在一定上下文长度中记忆、学习  
    长期记忆：常见向量数据库（RAG），大模型可获取的更多知识库，按需调用

#### 推理能力：任务规划Planning，一项复杂的任务拆解成多个子任务的能力  
子目标和分解  
    Chain of Thought CoT：提供任务分解的少量示例，利用大模型的上下文学习能力去模仿进行类似的任务分解和规划  
    Tree of Thought ToT：让大模型在每个节点做决策时分化出几个不同可能的策略，并采用DFS(深度优先搜索)或 BFS（广度优先搜索）去寻找可行策略，增强了大模型面对更复杂问题的决策能力  
    ReAct：边思考边行动  
    Self-Refine：把LLM输出的结果再输入到同一个LLM中，生成一个优化的版本  
    Reflextion框架：通过赋予智能体动态记忆和自我反思能力提升推理技巧，采用标准的强化学习设置，奖励模型提供简单的二元奖励（三个大模型：Actor负责生成，evaluator负责评估，Self-reflection负责优化和反思）

#### 	工具模块：Agent智能体通过工具与外界环境互动
		○ Plugin：结合LLM和专家模块，后者可能是其它LLM或特定工具（计算器\天气API等）
		○ Toolformer：对LLM进行微调，使其能够使用外部工具API
			§ meta提出的一个经过微调的模型，通过构建一个自监督的方法，教大模型学会自己调用API并省去大量标注工作
			§ 环节：API调用采样、API调用执行、API过滤
		○ Function Calling：功能增强了LLM的工具使用能力，定义一套工具API便于模型调用
		○ HuggingGPT：利用LLM作为任务规划器，通过连接各种现有的模型解决任务  
  让LLM充当控制器的新方法，让LLM使用语言作为通用接口，管理现有的AI模型（huggingface）以解决复杂的AI任务
